File Paths:
./README.md
./src/prompt_handling.rs
./src/git.rs
./src/validation.rs
./src/output.rs
./src/main.rs
./src/file_processing.rs
./src/cli.rs
./src/summary.rs

File Contents:


File Content of ./README.md:

# dirscribe

A CLI tool that collects and combines files with specific extensions from a directory into a single output. The output is copied to the clipboard by default.

## Features and Options

- Recursive traverse directory and filter by file extension
- Apply .gitignore 
- Configure subpaths to include or exclude
- Filter by positive and/or negative keyword filters
- Only output diff, between commit ids or from a specified commit id to the current state
- Embed output in prompt template
- Write output to file

## Installation

```bash
cargo install dirscribe
```

## Usage

Basic syntax:
```bash
dirscribe <comma_separated_suffixes_or_file_names_or_wildcard> [options]
```

Examples:
```bash
dirscribe md,py,Dockerfile
```

```bash
dirscribe "*"
```

### Demo (on Youtube)
[![Video showing how to use dirscribe](assets/public/thumbnail.jpg)](https://www.youtube.com/watch?v=rkXIZi1i3HI&t)

### Options

- `--exclude-paths`: Comma-separated paths to exclude
- `--include-paths`: Comma-separated paths to include
- `--or-keywords`: Only include files containing at least one of these keywords
- `--and-keywords`: Only include files containing all of these keywords
- `--exclude-keywords`: Exclude files containing any of these keywords
- `--diff-only`: Only process files that have Git changes
- `--start-commit-id`: Starting commit ID for Git diff range (optional). If provided alone without end-commit-id, diffs from this commit to the current working directory
- `--end-commit-id`: Ending commit ID for Git diff range (optional). Must be used with start-commit-id
- `--prompt-template-path`: Path to a template file that will wrap the output. The template must contain the placeholder `${${CONTENT}$}$` where the collected content should be inserted
- `--output-path`: Path where the output file should be written. If not provided, output will be copied to clipboard
- `--dont-use-gitignore`: include files covered by .gitignore

### Example with Diff Only

```bash
# Example using Git commit range
dirscribe rs,md \
  --diff-only \
  --start-commit-id abc123 \
  --end-commit-id def456
```

This will only process files that changed between commits abc123 and def456.

### Example with Prompt Template

```bash
dirscribe rs,md \
  --exclude-paths src/core,src/temp \
  --or-keywords "TODO,FIXME" \
  --prompt-template-path "summarize-issues-to-address-prompt.txt"
```

## Output Format

The output is in this format:

```
File Paths:
/path/to/file1.txt
/path/to/file2.md

File Contents:
File: /path/to/file1.txt
[Contents of file1.txt]

File: /path/to/file2.md
[Contents of file2.md]
```

If a prompt template path is specified, this output will be embedded in that template for the final output.

## Template

You can specify a template to embed the output in. The template should be a txt file that contains the string "${${CONTENT}$}$" (without quotation marks), and that string will be replaced with the output as shown above.

## License

MIT License


File Content of ./src/prompt_handling.rs:

use std::collections::HashMap;
use std::fs;

pub fn load_prompts(dir: &str) -> std::io::Result<HashMap<String, String>> {
    Ok(fs::read_dir(dir)?
        .filter_map(Result::ok)
        .filter(|e| e.path().is_file())
        .filter_map(|e| {
            let path = e.path();
            Some((
                path.file_stem()?.to_str()?.to_string(),
                fs::read_to_string(path).ok()?
            ))
        })
        .collect())
}


File Content of ./src/git.rs:

use std::io;
use std::path::{Path, PathBuf};
use git2::{Repository, Tree, Diff, DiffFormat};

pub fn get_diff_list(
    repo: &Repository,
    start_commit_id: Option<&str>,
    end_commit_id: Option<&str>,
) -> io::Result<Vec<PathBuf>> {
    let mut diff_list = Vec::new();
    
    // Helper function to get tree from commit ID
    let get_tree = |commit_id: &str| -> io::Result<Tree> {
        repo.revparse_single(commit_id)
            .map_err(|e| io::Error::new(io::ErrorKind::Other, e.message().to_string()))?
            .peel_to_commit()
            .map_err(|e| io::Error::new(io::ErrorKind::Other, e.message().to_string()))?
            .tree()
            .map_err(|e| io::Error::new(io::ErrorKind::Other, e.message().to_string()))
    };

    // Get the diff based on provided arguments
    let diff = match (start_commit_id, end_commit_id) {
        // Both None: compare working directory with HEAD
        (None, None) => {
            let head_tree = repo.head()
                .map_err(|e| io::Error::new(io::ErrorKind::Other, e.message().to_string()))?
                .peel_to_tree()
                .map_err(|e| io::Error::new(io::ErrorKind::Other, e.message().to_string()))?;
            
            repo.diff_tree_to_workdir_with_index(
                Some(&head_tree),
                None
            )
        },
        // Only old_commit provided: compare that commit with working directory
        (Some(old_id), None) => {
            let old_tree = get_tree(old_id)?;
            repo.diff_tree_to_workdir_with_index(
                Some(&old_tree),
                None
            )
        },
        // Both provided: compare the two commits directly
        (Some(old_id), Some(new_id)) => {
            let old_tree = get_tree(old_id)?;
            let new_tree = get_tree(new_id)?;
            repo.diff_tree_to_tree(
                Some(&old_tree),
                Some(&new_tree),
                None
            )
        },
        // Invalid case: old None but new Some - treat as comparing HEAD to new commit
        (None, Some(new_id)) => {
            let head_tree = repo.head()
                .map_err(|e| io::Error::new(io::ErrorKind::Other, e.message().to_string()))?
                .peel_to_tree()
                .map_err(|e| io::Error::new(io::ErrorKind::Other, e.message().to_string()))?;
            let new_tree = get_tree(new_id)?;
            repo.diff_tree_to_tree(
                Some(&head_tree),
                Some(&new_tree),
                None
            )
        }
    }.map_err(|e| io::Error::new(io::ErrorKind::Other, e.message().to_string()))?;
    
    // Collect changed files
    diff.foreach(
        &mut |delta, _| {
            if let Some(new_file) = delta.new_file().path() {
                diff_list.push(new_file.to_path_buf());
            }
            true
        },
        None,
        None,
        None,
    ).map_err(|e| io::Error::new(io::ErrorKind::Other, e.message().to_string()))?;
    
    Ok(diff_list)
}

pub fn get_diff_str(diff: &Diff) -> io::Result<String> {
    let mut diff_output = Vec::new();
    diff.print(DiffFormat::Patch, |_delta, _hunk, line| {
        if let Ok(content) = std::str::from_utf8(line.content()) {
            diff_output.extend_from_slice(content.as_bytes());
        }
        true
    }).map_err(|e| io::Error::new(io::ErrorKind::Other, e.message().to_string()))?;

    String::from_utf8(diff_output).map_err(|e| io::Error::new(io::ErrorKind::InvalidData, e))
}

pub fn filter_diff_for_file(diff_str: &str, file_path: &Path) -> String {
    let lines: Vec<&str> = diff_str.lines().collect();
    let mut result = Vec::new();
    let mut current_file_section = false;
    // Get just the filename component
    let file_name = file_path.file_name()
        .map(|s| s.to_string_lossy())
        .unwrap_or_default();

    for line in lines {
        if line.starts_with("diff --git") {
            // Check if this section is for our file
            current_file_section = line.contains(&*file_name);
            if current_file_section {
                result.push(line);
            }
        } else if current_file_section {
            // Keep adding lines until we hit the next diff section
            if line.starts_with("diff --git") {
                break;
            }
            result.push(line);
        }
    }

    result.join("\n")
}


File Content of ./src/validation.rs:

use std::path::{Path, PathBuf};
use crate::cli::Cli;
use git2::Repository;
use anyhow::Result;
use std::error::Error;
use std::fmt;

#[derive(Debug)]
pub struct ValidationError(String);

impl fmt::Display for ValidationError {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "{}", self.0)
    }
}

impl Error for ValidationError {}

impl From<String> for ValidationError {
    fn from(msg: String) -> Self {
        ValidationError(msg)
    }
}

impl From<&str> for ValidationError {
    fn from(msg: &str) -> Self {
        ValidationError(msg.to_string())
    }
}

pub fn validate_cli_args(cli: &Cli) -> Result<()> {
    // Validate suffixes
    validate_suffixes(&cli.suffixes)?;

    // Validate paths
    if let Some(template_path) = &cli.prompt_template_path {
        validate_template_path(template_path)?;
    }

    if let Some(output_path) = &cli.output_path {
        validate_output_path(output_path)?;
    }

    // Validate git-related arguments
    validate_git_args(
        cli.diff_only,
        &cli.start_commit_id,
        &cli.end_commit_id,
    )?;

    // Validate keywords
    validate_keywords(&cli.or_keywords, "or_keywords")?;
    validate_keywords(&cli.and_keywords, "and_keywords")?;
    validate_keywords(&cli.exclude_keywords, "exclude_keywords")?;

    // Validate exclude/include paths
    validate_path_filters(
        &cli.exclude_paths,
        &cli.include_paths,
    )?;

    Ok(())
}

fn validate_suffixes(suffixes: &str) -> Result<(), ValidationError> {
    if suffixes.is_empty() {
        return Err(ValidationError("Suffixes cannot be empty".to_string()));
    }

    if suffixes == "*" {
        return Ok(());
    }

    let parts: Vec<&str> = suffixes.split(',').collect();
    
    for suffix in parts {
        if suffix.is_empty() {
            return Err("Empty suffix found after splitting".into());
        }

        if !suffix.chars().all(|c| c.is_alphanumeric()) {
            return Err(format!("Invalid suffix '{}': must be alphanumeric", suffix).into());
        }

        if suffix.len() > 10 {
            return Err(format!("Suffix '{}' exceeds maximum length of 10", suffix).into());
        }
    }

    Ok(())
}

fn validate_template_path(path: &str) -> Result<(), ValidationError> {
    let path = Path::new(path);
    
    if !path.exists() {
        return Err(format!("Template file does not exist: {}", path.display()).into());
    }

    if !path.is_file() {
        return Err(format!("Template path is not a file: {}", path.display()).into());
    }

    // Check file size (e.g., max 1MB)
    if let Ok(metadata) = path.metadata() {
        if metadata.len() > 100_000_000 {
            return Err("Template file is too large (max 100MB)".into());
        }
    }

    Ok(())
}

fn validate_output_path(path: &str) -> Result<(), ValidationError> {
    let path = Path::new(path);
    
    // Check if path points to a directory
    if path.is_dir() {
        return Err(format!("Output path is a directory: {}", path.display()).into());
    }

    Ok(())
}

fn validate_git_args(
    diff_only: bool,
    start_commit: &Option<String>,
    end_commit: &Option<String>,
) -> Result<(), ValidationError> {

    if diff_only && start_commit.is_none() {
        return Err("--start-commit-id must be provided when using --diff-only".into());
    }
    if start_commit.is_some() && !diff_only {
        return Err("--diff-only must be set when using --start-commit-id".into());
    }
    if end_commit.is_some() && !diff_only {
        return Err("--diff-only must be set when using --end-commit-id".into());
    }
    if end_commit.is_some() && start_commit.is_none() {
        return Err("--start-commit-id must be set when using --end-commit-id".into());
    }

    // Verify we're in a git repository
    if diff_only {
        let repo = match Repository::open(".") {
            Ok(repo) => repo,
            Err(_) => return Err("Not a git repository".into()),
        };

        if let Some(start) = start_commit {
            validate_commit(&repo, start, "start_commit_id")?;
        }

        if let Some(end) = end_commit {
            validate_commit(&repo, end, "end_commit_id")?;
        }

        // If both commits provided, verify start is ancestor of end
        if let (Some(start), Some(end)) = (start_commit, end_commit) {
            let start_commit = repo
                .revparse_single(start)
                .map_err(|_| format!("Invalid start commit: {}", start))?
                .peel_to_commit()
                .map_err(|_| "Failed to parse start commit".to_string())?;

            let end_commit = repo
                .revparse_single(end)
                .map_err(|_| format!("Invalid end commit: {}", end))?
                .peel_to_commit()
                .map_err(|_| "Failed to parse end commit".to_string())?;

            if !repo.graph_descendant_of(end_commit.id(), start_commit.id())
                .map_err(|_| "Failed to check commit relationship".to_string())? {
                return Err("start_commit_id must be an ancestor of end_commit_id".into());
            }
        }

    }
    Ok(())
}

fn validate_commit(repo: &Repository, commit_id: &str, arg_name: &str) -> Result<(), ValidationError> {
    match repo.revparse_single(commit_id) {
        Ok(obj) => {
            if obj.as_commit().is_none() {
                return Err(format!("{} is not a valid commit", arg_name).into());
            }
        }
        Err(_) => {
            return Err(format!("Invalid {}: {}", arg_name, commit_id).into());
        }
    }
    Ok(())
}

fn validate_keywords(keywords: &Option<String>, field_name: &str) -> Result<(), ValidationError> {
    if let Some(keywords) = keywords {
        let parts: Vec<&str> = keywords.split(',').collect();
        
        for keyword in parts {
            if keyword.is_empty() {
                return Err(format!("Empty keyword found in {}", field_name).into());
            }

            if keyword.len() > 100 {
                return Err(format!("Keyword in {} exceeds maximum length of 100", field_name).into());
            }

            // Check for invalid characters (optional - adjust as needed)
            if keyword.chars().any(|c| !c.is_ascii()) {
                return Err(format!("Non-ASCII characters found in {} keyword: {}", field_name, keyword).into());
            }
        }
    }
    Ok(())
}

fn validate_path_filters(
    exclude_paths: &Option<String>,
    include_paths: &Option<String>,
) -> Result<(), ValidationError> {
    let mut all_paths = Vec::new();

    // Helper function to process paths
    let process_paths = |paths_str: &str, is_exclude: bool| -> Result<Vec<PathBuf>, ValidationError> {
        let paths: Vec<PathBuf> = paths_str
            .split(',')
            .filter(|s| !s.is_empty())
            .map(PathBuf::from)
            .collect();

        for path in &paths {
            // Normalize path
            let normalized = path.canonicalize().map_err(|_| {
                format!("{} path does not exist: {}", 
                    if is_exclude { "Exclude" } else { "Include" },
                    path.display()
                )
            })?;

            // Verify path is within project directory
            let current_dir = std::env::current_dir().map_err(|_| 
                "Failed to get current directory".to_string()
            )?;
            
            if !normalized.starts_with(current_dir) {
                return Err(format!("Path is outside project directory: {}", path.display()).into());
            }
        }

        Ok(paths)
    };

    if let Some(exclude) = exclude_paths {
        all_paths.extend(process_paths(exclude, true)?);
    }

    if let Some(include) = include_paths {
        let include_paths = process_paths(include, false)?;
        
        // Check for conflicts between include and exclude paths
        for include_path in &include_paths {
            if all_paths.iter().any(|p| include_path.starts_with(p)) {
                return Err(format!(
                    "Include path conflicts with exclude path: {}", 
                    include_path.display()
                ).into());
            }
        }
        
        all_paths.extend(include_paths);
    }

    Ok(())
}


File Content of ./src/output.rs:

use std::fs;
use anyhow::{Result, bail};
use clipboard::{ClipboardContext, ClipboardProvider};

pub fn write_to_clipboard(content: &str) -> Result<()> {
    let mut ctx: ClipboardContext = ClipboardProvider::new()
        .map_err(|e| anyhow::anyhow!("Failed to create clipboard context: {}", e))?;
    
    ctx.set_contents(content.to_owned())
        .map_err(|e| anyhow::anyhow!("Failed to set clipboard contents: {}", e))?;
    
    Ok(())
}

pub fn process_with_template(content: &str, template_path: &str) -> Result<String> {
    // Read the template file
    let template = fs::read_to_string(template_path)
        .map_err(|e| anyhow::anyhow!("Failed to read template file: {}", e))?;

    // Check for the required placeholder
    if !template.contains("${${CONTENT}$}$") {
        bail!("Template file must contain the placeholder '${{${{CONTENT}}$}}$'");
    }

    // Replace the placeholder with the content
    Ok(template.replace("${${CONTENT}$}$", content))
}


File Content of ./src/main.rs:

use std::fs::File;
mod cli;
mod git;
mod file_processing;
mod output;
mod prompt_handling;
mod summary; 
mod validation;
use cli::Cli;
use file_processing::process_directory;
use output::{write_to_clipboard, process_with_template};
use clap::Parser;
use validation::validate_cli_args;
use anyhow::{Result, Context};
use std::io::Write;
use std::path::PathBuf;
use prompt_handling::load_prompts;



#[tokio::main]
async fn main() -> Result<()> {
    let cli = Cli::parse();

    assert!(
        cli.suffixes == "*" || !cli.suffixes.chars().any(|s| s == '*'),
        "\"*\" can only be used alone, file extensions are specified without wildcard, like 'py,toml,js'"
    );

    if let Err(e) = validate_cli_args(&cli) {
        eprintln!("Error: {}", e);
        std::process::exit(1);
    }

    
    let suffixes: Vec<String> = cli.suffixes.split(',').map(String::from).collect();
    
    let exclude_paths: Vec<PathBuf> = match cli.exclude_paths {
        Some(s) => {
            if s.contains(',') {
                s.split(',').map(PathBuf::from).collect()
            } else {
                vec![PathBuf::from(s)]
            }
        }
        None => Vec::new()
    };

    let include_paths: Vec<PathBuf> = match cli.include_paths {
        Some(s) => {
            if s.contains(',') {
                s.split(',').map(PathBuf::from).collect()
            } else {
                vec![PathBuf::from(s)]
            }
        }
        None => Vec::new()
    };

    let or_keywords: Vec<String> = cli.or_keywords
        .map(|s| if s.contains(',') {
            s.split(',').map(String::from).collect()
        } else {
            vec![s]
        })
        .unwrap_or_default();

    let and_keywords: Vec<String> = cli.and_keywords
        .map(|s| if s.contains(',') {
            s.split(',').map(String::from).collect()
        } else {
            vec![s]
        })
        .unwrap_or_default();

    let exclude_keywords: Vec<String> = cli.exclude_keywords
        .map(|s| if s.contains(',') {
            s.split(',').map(String::from).collect()
        } else {
            vec![s]
        })
        .unwrap_or_default();

    // Read the file contents into a String
    let summarize_prompt_templates = load_prompts("prompts").context("Failed to load prompt templates")?;
    // Process directory and get the content string
    let content = process_directory(
        ".",
        &suffixes,
        cli.dont_use_gitignore,
        cli.summarize,
        summarize_prompt_templates,
        cli.apply,
        cli.diff_only,
        &exclude_paths,
        &include_paths,
        &or_keywords,
        &and_keywords,
        &exclude_keywords,
        cli.start_commit_id.as_deref(),
        cli.end_commit_id.as_deref()
    ).await?;

    let final_content = if let Some(template_path) = cli.prompt_template_path {
        process_with_template(&content, &template_path)?
    } else {
        content
    };


    if let Some(output_path) = cli.output_path {
        let mut output_file = File::create(&output_path)?;
        output_file.write_all(final_content.as_bytes())?;
        println!("Successfully processed directory and written output to {}", output_path);
    } else {
        write_to_clipboard(&final_content)?;
        println!("Successfully processed directory and copied output to clipboard");
    };
    Ok(())
}










File Content of ./src/file_processing.rs:

use std::fs;
use std::io::{self, Write, Cursor};
use anyhow::Context;
use std::path::{Path, PathBuf};
use ignore::WalkBuilder;
use std::collections::HashMap;
use git2::{Repository, Tree};
use crate::git::{get_diff_list, get_diff_str, filter_diff_for_file};
use crate::summary::get_summaries;


pub async fn process_directory(
    dir_path: &str,
    suffixes: &[String],
    dont_use_gitignore: bool,
    summarize: bool,
    summarize_prompt_templates: HashMap<String, String>,
    _apply: bool,
    diff_only: bool,
    exclude_paths: &[PathBuf],
    include_paths: &[PathBuf],
    or_keywords: &[String],
    and_keywords: &[String],
    exclude_keywords: &[String],
    start_commit_id: Option<&str>,
    end_commit_id: Option<&str>
) -> anyhow::Result<String> {
    let mut output = Cursor::new(Vec::new());
    let dir_path = Path::new(dir_path);
    
    let repo = if diff_only {
        Some(Repository::open(dir_path).context("Failed to open git repository")?)
    } else {
        None
    };

    if !dir_path.exists() {
        return Err(anyhow::anyhow!("Directory not found"));
    }

    let mut diff_list = Vec::new();
    if diff_only {
        if let Some(repo) = &repo {
            diff_list = get_diff_list(repo, start_commit_id, end_commit_id)?;
        }
    }

    // First, collect all valid file paths
    let mut valid_files = Vec::new();
    
    let walker = WalkBuilder::new(dir_path)
        .hidden(false)
        .git_ignore(!dont_use_gitignore)
        .build();

    for result in walker {
        match result {
            Ok(entry) => {
                let path = entry.path();
                
                // Skip if diff_only is true and path is not in diff_list
                if diff_only {
                    if let Ok(relative_path) = path.strip_prefix(dir_path) {
                        if !diff_list.contains(&relative_path.to_path_buf()) {
                            continue;
                        }
                    }
                }

                let should_include = if path.is_dir() {
                    false
                } else if suffixes.contains(&"*".to_string()) {
                    // If wildcard is specified, check if it's a text-like file
                    is_likely_text_file(path)
                } else if let Some(file_suffix) = path.extension() {
                    suffixes.iter().any(|s| s == file_suffix.to_str().unwrap_or(""))
                } else {
                    if let Some(filename) = path.file_name() {
                        suffixes.iter().any(|s| s == filename.to_str().unwrap_or(""))
                    } else {
                        false
                    }
                };

                if should_include {
                    // Get relative path from base directory
                    if let Ok(relative_path) = path.strip_prefix(dir_path) {
                        let relative_path_str = relative_path.to_string_lossy();
                        
                        // Skip if path matches any exclude pattern
                        if exclude_paths.iter().any(|excluded| 
                            relative_path_str.starts_with(&excluded.to_string_lossy().as_ref())
                        ) {
                            continue;
                        }
                        
                        // Skip if include patterns exist and path doesn't match any
                        if !include_paths.is_empty() {
                            let is_included = include_paths.iter().any(|included|
                                relative_path_str.starts_with(&included.to_string_lossy().as_ref())
                            );
                            if !is_included {
                                continue;
                            }
                        }

                        // Check keyword filters before adding to valid files
                        if check_for_keywords(
                            &path.to_path_buf(),
                            or_keywords,
                            and_keywords,
                            exclude_keywords,
                        )? {
                            valid_files.push(path.to_path_buf());
                        }
                    }
                }
            }
            Err(err) => eprintln!("Error walking directory: {}", err),
        }
    }

    // Write all file paths at the top
    writeln!(output, "File Paths:")?;
    for file_path in &valid_files {
        writeln!(output, "{}", file_path.display())?;
    }
    writeln!(output)?;
    if !summarize {
        writeln!(output, "File Contents:")?;
    } else {
        writeln!(output, "File Summaries:")?;
    }
    writeln!(output)?;

    let file_contents: HashMap<String, String> = valid_files
        .iter()
        .filter_map(|file_path| {
            let path_string = file_path.to_string_lossy().into_owned();
            match process_file(
                file_path,
                summarize,
                summarize_prompt_templates.clone(),
                diff_only,
                repo.as_ref(),
                start_commit_id,
                end_commit_id
            ) {
                Ok(content) => Some((path_string, content)),
                Err(e) => {
                    eprintln!("Error processing file {}: {}", file_path.display(), e);
                    None
                }
            }
        })
        .collect();

    // Generate output string maintaining file path order
    let result = if summarize {
        let valid_file_strings: Vec<String> = valid_files.iter()
            .map(|path| path.to_string_lossy().into_owned())
            .collect();
            
        let summaries = if !diff_only {
            get_summaries(valid_file_strings.clone(), file_contents.clone(), summarize_prompt_templates["summary-0.1.txt"].clone()).await?
        } else {
            get_summaries(valid_file_strings, file_contents.clone(), summarize_prompt_templates["summary-diff-0.1.txt"].clone()).await?
        };
        
        // Use the original valid_files order
        valid_files.iter().zip(summaries.iter())
            .map(|(file, summary)| {
                format!("\nSummary of {}:\n\n{}\n", file.display(), summary)
            })
            .collect::<Vec<String>>()
            .join("")
    } else if diff_only {
        valid_files.iter()
            .filter_map(|file| {
                let path_string = file.to_string_lossy().into_owned();
                file_contents.get(&path_string)
                    .map(|content| format!("\nDiff of {}:\n\n{}\n", file.display(), content))
            })
            .collect::<Vec<String>>()
            .join("")
    } else {
        valid_files.iter()
            .filter_map(|file| {
                let path_string = file.to_string_lossy().into_owned();
                file_contents.get(&path_string)
                    .map(|content| format!("\nFile Content of {}:\n\n{}\n", file.display(), content))
            })
            .collect::<Vec<String>>()
            .join("")
    };

    write!(output, "{}", result)?;
    
    String::from_utf8(output.into_inner())
        .map_err(|e| io::Error::new(io::ErrorKind::InvalidData, e))
        .map_err(Into::into)
}

pub fn process_file(
    file_path: &PathBuf,
    _summarize: bool, // Fixed parameter order to match usage
    _summarize_prompt_templates: HashMap<String, String>,
    diff_only: bool,
    repo: Option<&Repository>,
    start_commit_id: Option<&str>,
    end_commit_id: Option<&str>
) -> io::Result<String> {
    let _relative_path = if let Some(repo) = repo {
        let repo_workdir = repo.workdir().ok_or_else(|| {
            io::Error::new(io::ErrorKind::Other, "Could not get repository working directory")
        })?;
        
        let full_path = fs::canonicalize(file_path)?;
        let relative_path = full_path.strip_prefix(fs::canonicalize(repo_workdir)?)
            .map_err(|_| io::Error::new(io::ErrorKind::Other, "File not in repository"))?;
            
        relative_path.to_path_buf()
    } else {
        file_path.clone()
    };

    let contents = if !diff_only {
        fs::read_to_string(file_path)?
    } else {
        if let Some(repo) = repo {
            let get_tree = |commit_id: &str| -> io::Result<Tree> {
                repo.revparse_single(commit_id)
                    .map_err(|e| io::Error::new(io::ErrorKind::Other, e.message().to_string()))?
                    .peel_to_commit()
                    .map_err(|e| io::Error::new(io::ErrorKind::Other, e.message().to_string()))?
                    .tree()
                    .map_err(|e| io::Error::new(io::ErrorKind::Other, e.message().to_string()))
            };

            let diff = match (start_commit_id, end_commit_id) {
                (None, None) => {
                    let head_tree = repo.head()
                        .map_err(|e| io::Error::new(io::ErrorKind::Other, e.message().to_string()))?
                        .peel_to_tree()
                        .map_err(|e| io::Error::new(io::ErrorKind::Other, e.message().to_string()))?;
                    
                    repo.diff_tree_to_workdir_with_index(Some(&head_tree), None)
                },
                (Some(old_id), None) => {
                    let old_tree = get_tree(old_id)?;
                    repo.diff_tree_to_workdir_with_index(Some(&old_tree), None)
                },
                (Some(old_id), Some(new_id)) => {
                    let old_tree = get_tree(old_id)?;
                    let new_tree = get_tree(new_id)?;
                    repo.diff_tree_to_tree(Some(&old_tree), Some(&new_tree), None)
                },
                (None, Some(new_id)) => {
                    let head_tree = repo.head()
                        .map_err(|e| io::Error::new(io::ErrorKind::Other, e.message().to_string()))?
                        .peel_to_tree()
                        .map_err(|e| io::Error::new(io::ErrorKind::Other, e.message().to_string()))?;
                    let new_tree = get_tree(new_id)?;
                    repo.diff_tree_to_tree(Some(&head_tree), Some(&new_tree), None)
                }
            }.map_err(|e| io::Error::new(io::ErrorKind::Other, e.message().to_string()))?;

            let diff_str = get_diff_str(&diff)?;
            filter_diff_for_file(&diff_str, file_path) // Removed unnecessary semicolon
        } else {
            String::new() // Added else branch for when repo is None
        }
    };

    Ok(contents)
}


pub fn check_for_keywords(
    file_path: &PathBuf,
    or_keywords: &[String],
    and_keywords: &[String],
    exclude_keywords: &[String],
) -> io::Result<bool> {


    let contents = fs::read_to_string(file_path)?;

    // Check exclude keywords - skip if any are present
    if exclude_keywords.iter().any(|keyword| contents.contains(keyword)) {
        return Ok(false);
    }
    
    // Check OR keywords - at least one must be present
    if !or_keywords.is_empty() {
        let contains_or_keyword = or_keywords.iter().any(|keyword| contents.contains(keyword));
        if !contains_or_keyword {
            return Ok(false);
        }
    }

    // Check AND keywords - all must be present
    if !and_keywords.is_empty() {
        let contains_all_keywords = and_keywords.iter().all(|keyword| contents.contains(keyword));
        if !contains_all_keywords {
            return Ok(false);
        }
    }

    Ok(true)
}

// Add this function at the top of file_processing.rs
fn is_likely_text_file(path: &Path) -> bool {
    // Common text file extensions
    const TEXT_EXTENSIONS: &[&str] = &[
        // Programming languages
        "rs", "py", "js", "ts", "java", "c", "cpp", "h", "hpp", "cs", "go", "rb", "php", "swift",
        "kt", "scala", "sh", "bash", "pl", "r", "sql", "m", "mm",
        // Web
        "html", "htm", "css", "scss", "sass", "less", "xml", "svg",
        // Data formats
        "json", "yaml", "yml", "toml", "ini", "conf", "config",
        // Documentation
        "md", "markdown", "txt", "rtf", "rst", "asciidoc", "adoc",
        // Config files
        "gitignore", "env", "dockerignore", "editorconfig",
        // Build files
        "cmake", "make", "mak", "gradle",
    ];

    // Always consider files without extension that are commonly text
    const EXTENSION_LESS_TEXT_FILES: &[&str] = &[
        "Dockerfile", "Makefile", "README", "LICENSE", "Cargo.lock", "package.json",
        ".gitignore", ".env", ".dockerignore", ".editorconfig"
    ];

    if let Some(file_name) = path.file_name().and_then(|n| n.to_str()) {
        // Check extension-less files first
        if EXTENSION_LESS_TEXT_FILES.contains(&file_name) {
            return true;
        }
    }

    // Check file extension
    if let Some(ext) = path.extension().and_then(|e| e.to_str()) {
        if TEXT_EXTENSIONS.contains(&ext.to_lowercase().as_str()) {
            return true;
        }
    }

    // For files without extension or unknown extensions, try to read a small sample
    // and check if it contains only valid UTF-8 text
    if let Ok(file) = std::fs::File::open(path) {
        use std::io::Read;
        let mut buffer = [0u8; 1024];
        let mut handle = file;
        
        // Read first 1024 bytes
        if handle.read(&mut buffer).is_ok() {
            // Check if content is valid UTF-8
            return String::from_utf8(buffer.to_vec()).is_ok();
        }
    }

    false
}


File Content of ./src/cli.rs:

use clap::Parser;

#[derive(Parser)]
#[command(author, version, about, long_about = None)]
pub struct Cli {
    /// Comma-separated list of file extensions to process (e.g., "txt,md,rs")
    pub suffixes: String,

    /// Path to prompt template file
    #[arg(long)]
    pub prompt_template_path: Option<String>,

    /// Path to output path
    #[arg(long)]
    pub output_path: Option<String>,

    /// Include files that are ignored by default based on .gitignore rules
    #[arg(long, default_value_t = false)]
    pub dont_use_gitignore: bool,

    /// Summarize file contents
    #[arg(long, default_value_t = false)]
    pub summarize: bool,

    /// Apply summaries to code files
    #[arg(long, default_value_t = false)]
    pub apply: bool,

    /// Comma-separated list of paths to exclude
    #[arg(long)]
    pub exclude_paths: Option<String>,

    /// Comma-separated list of paths to include
    #[arg(long)]
    pub include_paths: Option<String>,

    /// Comma-separated list of keywords - only include files containing at least one keyword
    #[arg(long)]
    pub or_keywords: Option<String>,

    /// Comma-separated list of keywords - only include files containing all keywords
    #[arg(long)]
    pub and_keywords: Option<String>,

    /// Comma-separated list of keywords - exclude files containing any of these keywords
    #[arg(long)]
    pub exclude_keywords: Option<String>,

    /// Only show files that have differences
    #[arg(long, default_value_t = false)]
    pub diff_only: bool,

    /// Starting commit hash for diff comparison
    #[arg(long)]
    pub start_commit_id: Option<String>,

    /// Ending commit hash for diff comparison
    #[arg(long)]
    pub end_commit_id: Option<String>,
}


File Content of ./src/summary.rs:

use reqwest::Client;
use serde::{Deserialize, Serialize};
use anyhow::{Context, Result};
use std::env;
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::Semaphore;

#[derive(Serialize)]
struct DeepseekRequest {
    model: String,
    messages: Vec<Message>,
    temperature: f32,
}

#[derive(Serialize)]
struct Message {
    role: String,
    content: String,
}

#[derive(Deserialize)]
struct DeepseekResponse {
    choices: Vec<Choice>,
}

#[derive(Deserialize)]
struct Choice {
    message: ResponseMessage,
}

#[derive(Deserialize)]
struct ResponseMessage {
    content: String,
}

pub async fn get_summaries(valid_files: Vec<String>, file_contents: HashMap<String, String>, prompt_template: String) -> Result<Vec<String>> {
    let semaphore = Arc::new(Semaphore::new(10));
    
    let mut handles = Vec::new();
    
    for file_path in valid_files {
        let permit = semaphore.clone().acquire_owned().await?;
        let content = file_contents.get(&file_path).unwrap_or(&String::new()).clone();
        let template = prompt_template.clone();
        let file_path_clone = file_path.clone();
        
        let handle = tokio::spawn(async move {
            let result = get_summary(content, template).await;
            drop(permit);
            match result {
                Ok(summary) => summary,
                Err(e) => format!("Error processing file {}: {}", file_path_clone, e)
            }
        });
        
        handles.push(handle);
    }
    
    let mut results = Vec::new();
    for handle in handles {
        results.push(handle.await?);
    }
    
    Ok(results)
}

pub async fn get_summary(text: String, prompt_template: String) -> Result<String> {
    // Create API client
    let client = Client::new();
    
    // Replace placeholder in template with actual text
    let prompt = prompt_template.replace("{text}", &text);
    
    // Construct request payload
    let request = DeepseekRequest {
        model: "deepseek-chat".to_string(),
        messages: vec![Message {
            role: "user".to_string(),
            content: prompt,
        }],
        temperature: 0.7,
    };
    
    // Send request to Deepseek API
    let response = client
        .post("https://api.deepseek.com/v1/chat/completions")
        .header(
            "Authorization",
            format!("Bearer {}", env::var("DEEPSEEK_API_KEY").context("DEEPSEEK_API_KEY not set")?)
        )
        .json(&request)
        .send()
        .await
        .context("Failed to send request to Deepseek API")?;
    
    // Parse response
    let deepseek_response = response
        .json::<DeepseekResponse>()
        .await
        .context("Failed to parse Deepseek API response")?;
    
    // Extract summary from response
    let summary = deepseek_response
        .choices
        .first()
        .context("No response choices available")?
        .message
        .content
        .clone();
    
    Ok(summary)
}


